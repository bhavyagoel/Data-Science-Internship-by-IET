{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Review4Classifier.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iy1_uoartZYe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import BaggingClassifier, AdaBoostClassifier, RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
        "from sklearn.metrics import f1_score, make_scorer, accuracy_score\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ct-km9IYtoLN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pd.read_csv(\"X_train.csv\")"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7HGq5TSuJGy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "outputId": "376d09e1-6124-4cd6-d527-e026f91e7d9b"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ssc_p</th>\n",
              "      <th>hsc_p</th>\n",
              "      <th>degree_p</th>\n",
              "      <th>etest_p</th>\n",
              "      <th>mba_p</th>\n",
              "      <th>salary</th>\n",
              "      <th>gender_M</th>\n",
              "      <th>ssc_b_Others</th>\n",
              "      <th>hsc_b_Others</th>\n",
              "      <th>hsc_s_Commerce</th>\n",
              "      <th>hsc_s_Science</th>\n",
              "      <th>degree_t_Others</th>\n",
              "      <th>degree_t_Sci&amp;Tech</th>\n",
              "      <th>workex_Yes</th>\n",
              "      <th>specialisation_Mkt&amp;HR</th>\n",
              "      <th>status_Placed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.148760</td>\n",
              "      <td>-0.727273</td>\n",
              "      <td>-0.680851</td>\n",
              "      <td>-0.385078</td>\n",
              "      <td>0.106195</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.816556</td>\n",
              "      <td>1.101653</td>\n",
              "      <td>1.043636</td>\n",
              "      <td>0.659574</td>\n",
              "      <td>0.515042</td>\n",
              "      <td>-0.141593</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.132450</td>\n",
              "      <td>0.247934</td>\n",
              "      <td>-0.181818</td>\n",
              "      <td>0.170213</td>\n",
              "      <td>-0.505415</td>\n",
              "      <td>0.035398</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.728477</td>\n",
              "      <td>-1.074380</td>\n",
              "      <td>-1.272727</td>\n",
              "      <td>-0.212766</td>\n",
              "      <td>-0.309266</td>\n",
              "      <td>-0.849558</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.245033</td>\n",
              "      <td>0.710744</td>\n",
              "      <td>0.663636</td>\n",
              "      <td>1.097872</td>\n",
              "      <td>-0.782190</td>\n",
              "      <td>0.654867</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      ssc_p     hsc_p  ...  specialisation_Mkt&HR  status_Placed\n",
              "0  0.000000  2.148760  ...                      1              1\n",
              "1  0.816556  1.101653  ...                      0              1\n",
              "2 -0.132450  0.247934  ...                      0              1\n",
              "3 -0.728477 -1.074380  ...                      1              0\n",
              "4  1.245033  0.710744  ...                      0              1\n",
              "\n",
              "[5 rows x 16 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_Q8Xs23uKNQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = data.iloc[:,[0,1,2,3,4,6,7,8,9,10,11,12,13,14]]\n",
        "y = data.iloc[:,[15]]"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e47pCs4DuVkX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 0)"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "heMdNOqxubSb",
        "colab_type": "text"
      },
      "source": [
        "## Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNNsC41nuY1X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "5ff6bbd5-f209-43c5-ba95-1ce09c2f1f60"
      },
      "source": [
        "model = LogisticRegression()\n",
        "features = SelectFromModel(model)\n",
        "features.fit(x_train.values, y_train.values)\n",
        "selected_feat = x_train.columns[(features.get_support())]\n",
        "xFeatTrain = x_train[selected_feat].values\n",
        "xFeatTest = x_test[selected_feat].values\n",
        "model.fit(xFeatTrain, y_train.values)\n",
        "pred = model.predict(xFeatTest)\n",
        "print(\"Accuracy on testing data:\\t {:f}\".format(accuracy_score(y_test, pred)))\n",
        "print(\"F-score on testing data:\\t {:f}\".format(f1_score(y_test, pred)))"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy on testing data:\t 0.697674\n",
            "F-score on testing data:\t 0.779661\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yCOMVquMvNeX",
        "colab_type": "text"
      },
      "source": [
        "## Gaussian NB"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJft_1XXujir",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "ce54cfef-59a6-4867-d1dd-a6a65f3d0dbc"
      },
      "source": [
        "naive = GaussianNB()\n",
        "scorer = make_scorer(f1_score)\n",
        "param = {'var_smoothing' : [1e-9, 5e-9, 1e-8, 5e-8, 1e-7]}\n",
        "model = GridSearchCV(naive, param, scoring=scorer, cv=5)\n",
        "model.fit(x_train.values, y_train.values)\n",
        "print(model.best_params_)\n",
        "print(model.best_score_)\n",
        "model = model.best_estimator_\n",
        "pred = model.predict(x_test.values)\n",
        "print(\"Accuracy on testing data:\\t {:f}\".format(accuracy_score(y_test, pred)))\n",
        "print(\"F-score on testing data:\\t {:f}\".format(f1_score(y_test, pred)))"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'var_smoothing': 1e-09}\n",
            "0.8739277766025486\n",
            "Accuracy on testing data:\t 0.744186\n",
            "F-score on testing data:\t 0.792453\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5MMLYMZw4Qc",
        "colab_type": "text"
      },
      "source": [
        "## Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bx5w5lb-wKXN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "149f1ca0-9853-4ced-e5f3-c3f308615c0f"
      },
      "source": [
        "tree = DecisionTreeClassifier()\n",
        "scorer = make_scorer(f1_score)\n",
        "param = {'criterion' : ['gini', 'entropy'], 'splitter': [ 'best', 'random'], \n",
        "                 'max_depth':[None,3,6,9,12], 'min_samples_split':[50,30,10,5, 2], \n",
        "                 'min_samples_leaf':[1,5,9,12], 'min_weight_fraction_leaf':[0, 0.1, 0.2, 0.5], \n",
        "                 'max_features':['auto', 'sqrt', 'log2'], 'max_leaf_nodes':[None, 50, 100, 10], \n",
        "                 'min_impurity_decrease':[0.0, 0.5, 1.0, 1.5]}\n",
        "\n",
        "model = RandomizedSearchCV(tree, param, scoring=scorer, cv=5)\n",
        "model.fit(x_train.values, y_train.values)\n",
        "print(model.best_params_)\n",
        "print(model.best_score_)\n",
        "model = model.best_estimator_\n",
        "pred = model.predict(x_test.values)\n",
        "print(\"Accuracy on testing data:\\t {:f}\".format(accuracy_score(y_test, pred)))\n",
        "print(\"F-score on testing data:\\t {:f}\".format(f1_score(y_test, pred)))"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'splitter': 'best', 'min_weight_fraction_leaf': 0.1, 'min_samples_split': 2, 'min_samples_leaf': 9, 'min_impurity_decrease': 1.0, 'max_leaf_nodes': None, 'max_features': 'sqrt', 'max_depth': None, 'criterion': 'entropy'}\n",
            "0.8259302552113773\n",
            "Accuracy on testing data:\t 0.627907\n",
            "F-score on testing data:\t 0.771429\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bK18ItKQwzUR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "00f14497-4301-4498-dba5-7aee6cc9d6e8"
      },
      "source": [
        "features = SelectFromModel(model)\n",
        "features.fit(x_train.values, y_train.values)\n",
        "selected_feat = x_train.columns[(features.get_support())]\n",
        "xFeatTrain = x_train[selected_feat].values\n",
        "xFeatTest = x_test[selected_feat].values\n",
        "model.fit(xFeatTrain, y_train.values)\n",
        "pred = model.predict(xFeatTest)\n",
        "print(\"Accuracy on testing data:\\t {:f}\".format(accuracy_score(y_test, pred)))\n",
        "print(\"F-score on testing data:\\t {:f}\".format(f1_score(y_test, pred)))"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy on testing data:\t 0.627907\n",
            "F-score on testing data:\t 0.771429\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQtpL5iOxw3I",
        "colab_type": "text"
      },
      "source": [
        "## Bagging Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oeXSCJCHxfZO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3b40c930-546e-4924-eeb4-e806277dc992"
      },
      "source": [
        "bagging = BaggingClassifier()\n",
        "param = {'n_estimators':[10,100, 200, 300, 400], 'max_samples':[1, 10, 50, 100], \n",
        "          'max_features':[1,2], 'bootstrap':[True, False], 'bootstrap_features':[True, False], \n",
        "          'oob_score':[False, True], 'warm_start':[True, False], 'n_jobs':[None, -1, 1, 2, 4], \n",
        "          'verbose':[0,1]}\n",
        "model = RandomizedSearchCV(bagging, param, scoring=scorer, cv=5)\n",
        "model.fit(x_train.values, y_train.values)\n",
        "print(\"*****************************************************\")\n",
        "print(model.best_params_)\n",
        "print(model.best_score_)\n",
        "model = model.best_estimator_\n",
        "pred = model.predict(x_test.values)\n",
        "\n",
        "print(\"Accuracy on testing data:\\t {:f}\".format(accuracy_score(y_test, pred)))\n",
        "print(\"F-score on testing data:\\t {:f}\".format(f1_score(y_test, pred)))\n",
        "print(\"*****************************************************\")\n"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
            "[Parallel(n_jobs=4)]: Done   2 out of   4 | elapsed:    0.1s remaining:    0.1s\n",
            "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:    0.5s finished\n",
            "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
            "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
            "[Parallel(n_jobs=4)]: Done   2 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
            "[Parallel(n_jobs=4)]: Done   2 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
            "[Parallel(n_jobs=4)]: Done   2 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
            "[Parallel(n_jobs=4)]: Done   2 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
            "[Parallel(n_jobs=4)]: Done   2 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
            "[Parallel(n_jobs=4)]: Done   2 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
            "[Parallel(n_jobs=4)]: Done   2 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
            "[Parallel(n_jobs=4)]: Done   2 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.4s remaining:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.4s finished\n",
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.2s remaining:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.2s finished\n",
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.4s remaining:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.4s finished\n",
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.2s remaining:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.2s finished\n",
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.4s remaining:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.4s finished\n",
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.2s remaining:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.2s finished\n",
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.4s remaining:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.4s finished\n",
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.2s remaining:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.2s finished\n",
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.4s remaining:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.4s finished\n",
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.2s remaining:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.2s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.5s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.5s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.5s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.5s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.5s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
            "[Parallel(n_jobs=4)]: Done   2 out of   4 | elapsed:    0.6s remaining:    0.6s\n",
            "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:    0.9s finished\n",
            "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
            "[Parallel(n_jobs=4)]: Done   2 out of   4 | elapsed:    0.4s remaining:    0.4s\n",
            "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:    0.7s finished\n",
            "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
            "[Parallel(n_jobs=4)]: Done   2 out of   4 | elapsed:    0.5s remaining:    0.5s\n",
            "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:    0.6s finished\n",
            "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
            "[Parallel(n_jobs=4)]: Done   2 out of   4 | elapsed:    0.2s remaining:    0.2s\n",
            "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:    0.2s finished\n",
            "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
            "[Parallel(n_jobs=4)]: Done   2 out of   4 | elapsed:    0.6s remaining:    0.6s\n",
            "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:    0.6s finished\n",
            "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
            "[Parallel(n_jobs=4)]: Done   2 out of   4 | elapsed:    0.1s remaining:    0.1s\n",
            "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:    0.2s finished\n",
            "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
            "[Parallel(n_jobs=4)]: Done   2 out of   4 | elapsed:    0.6s remaining:    0.6s\n",
            "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:    0.6s finished\n",
            "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
            "[Parallel(n_jobs=4)]: Done   2 out of   4 | elapsed:    0.1s remaining:    0.1s\n",
            "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:    0.2s finished\n",
            "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
            "[Parallel(n_jobs=4)]: Done   2 out of   4 | elapsed:    0.5s remaining:    0.5s\n",
            "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:    0.6s finished\n",
            "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
            "[Parallel(n_jobs=4)]: Done   2 out of   4 | elapsed:    0.2s remaining:    0.2s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*****************************************************\n",
            "{'warm_start': False, 'verbose': 0, 'oob_score': True, 'n_jobs': 2, 'n_estimators': 10, 'max_samples': 100, 'max_features': 2, 'bootstrap_features': False, 'bootstrap': True}\n",
            "0.8422944124961042\n",
            "Accuracy on testing data:\t 0.627907\n",
            "F-score on testing data:\t 0.771429\n",
            "*****************************************************\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:    0.2s finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2MAKxSYwzkQr",
        "colab_type": "text"
      },
      "source": [
        "## Ada Boost Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-jCcUJAx1nq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "1765bd87-7af3-46cb-a8ab-09bf5c7a7e5a"
      },
      "source": [
        "ada = AdaBoostClassifier()\n",
        "param = {'n_estimators':[10,100, 200, 300, 400], 'learning_rate':[1.0, 1.5, 2], \n",
        "            'algorithm':['SAMME', 'SAMME.R']}\n",
        "model = RandomizedSearchCV(ada, param, scoring=scorer, cv=5)\n",
        "model.fit(x_train.values, y_train.values)\n",
        "print(\"*****************************************************\")\n",
        "print(model.best_params_)\n",
        "print(model.best_score_)\n",
        "model = model.best_estimator_\n",
        "pred = model.predict(x_test.values)\n",
        "\n",
        "print(\"Accuracy on testing data:\\t {:f}\".format(accuracy_score(y_test, pred)))\n",
        "print(\"F-score on testing data:\\t {:f}\".format(f1_score(y_test, pred)))\n",
        "print(\"*****************************************************\")"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "*****************************************************\n",
            "{'n_estimators': 200, 'learning_rate': 1.5, 'algorithm': 'SAMME'}\n",
            "0.9201835451161597\n",
            "Accuracy on testing data:\t 0.790698\n",
            "F-score on testing data:\t 0.842105\n",
            "*****************************************************\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bbocV-GKznrr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "fc8920cd-71ed-4038-a40a-c2c448faf4c2"
      },
      "source": [
        "features = SelectFromModel(model)\n",
        "features.fit(x_train.values, y_train.values)\n",
        "selected_feat = x_train.columns[(features.get_support())]\n",
        "xFeatTrain = x_train[selected_feat].values\n",
        "xFeatTest = x_test[selected_feat].values\n",
        "model.fit(xFeatTrain, y_train.values)\n",
        "pred = model.predict(xFeatTest)\n",
        "print(\"Accuracy on testing data:\\t {:f}\".format(accuracy_score(y_test, pred)))\n",
        "print(\"F-score on testing data:\\t {:f}\".format(f1_score(y_test, pred)))"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy on testing data:\t 0.767442\n",
            "F-score on testing data:\t 0.821429\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZsOIr_0fz612",
        "colab_type": "text"
      },
      "source": [
        "## Random Forest Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-lSNiANzxRi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 992
        },
        "outputId": "14ef77ed-6e14-4adf-99c6-4896cca7be56"
      },
      "source": [
        "forest = RandomForestClassifier()\n",
        "param = {'n_estimators':[10,100, 200, 300, 400], 'criterion':['gini', 'entropy'], \n",
        "               'max_depth':[None,3,6,9,12], 'min_samples_split':[50,30,10,5, 2],\n",
        "               'min_samples_leaf':[1,5,9,12], 'min_weight_fraction_leaf':[0, 0.1, 0.2, 0.5],\n",
        "               'max_features':['auto', 'sqrt', 'log2'], 'max_leaf_nodes':[None, 50, 100, 10], \n",
        "               'min_impurity_decrease':[0.0, 0.5, 1.0, 1.5], 'bootstrap':[True, False],\n",
        "               'oob_score':[False, True], 'n_jobs':[None, -1, 1, 2, 4], 'verbose':[0,1], \n",
        "               'warm_start':[True, False], 'class_weight':['balanced', 'balanced_subsample'], \n",
        "               'ccp_alpha':[0.0, 0.1, 0.5, 1], 'max_samples':[1, 10, 50, 100]}\n",
        "model = RandomizedSearchCV(forest, param, scoring=scorer, cv=5)\n",
        "model.fit(x_train.values, y_train.values)\n",
        "print(\"*****************************************************\")\n",
        "print(model.best_params_)\n",
        "print(model.best_score_)\n",
        "model = model.best_estimator_\n",
        "pred = model.predict(x_test.values)\n",
        "\n",
        "print(\"Accuracy on testing data:\\t {:f}\".format(accuracy_score(y_test, pred)))\n",
        "print(\"F-score on testing data:\\t {:f}\".format(f1_score(y_test, pred)))\n",
        "print(\"*****************************************************\")"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.2s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.2s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.2s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.2s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.2s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.2s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*****************************************************\n",
            "{'warm_start': False, 'verbose': 1, 'oob_score': True, 'n_jobs': 1, 'n_estimators': 200, 'min_weight_fraction_leaf': 0.1, 'min_samples_split': 30, 'min_samples_leaf': 9, 'min_impurity_decrease': 1.5, 'max_samples': 1, 'max_leaf_nodes': 100, 'max_features': 'sqrt', 'max_depth': None, 'criterion': 'entropy', 'class_weight': 'balanced', 'ccp_alpha': 0.0, 'bootstrap': True}\n",
            "0.8259302552113773\n",
            "Accuracy on testing data:\t 0.627907\n",
            "F-score on testing data:\t 0.771429\n",
            "*****************************************************\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJVGnsmE0WCf",
        "colab_type": "text"
      },
      "source": [
        "## Gradient Boosting Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L09MTYWE0HX5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0ba7464c-cfd7-4438-b368-9869af800a29"
      },
      "source": [
        "boosting = GradientBoostingClassifier()\n",
        "param = {'loss':['deviance', 'exponential'], 'learning_rate':[0.1, 0.3, 0.6, 0.9], \n",
        "                 'n_estimators':[10, 100, 200, 300, 400], 'subsample':[0.2, 0.4, 0.8, 1.0], \n",
        "                 'criterion':['friedman_mse', 'mse', 'mae'], 'min_samples_split':[50,30,10,5, 2],\n",
        "                 'min_samples_leaf':[1,5,9,12], 'min_weight_fraction_leaf':[0, 0.1, 0.2, 0.5], \n",
        "                 'max_depth':[None,3,6,9,12], 'min_impurity_decrease':[0.0, 0.5, 1.0, 1.5], \n",
        "                 'max_features':['auto', 'sqrt', 'log2'], 'verbose':[0,1], 'max_leaf_nodes':[None, 50, 100, 10],\n",
        "                 'warm_start':[True, False], 'validation_fraction':[0.1, 0.4, 0.8, 1.2], \n",
        "                 'n_iter_no_change':[None, 1, 2, 3, 4], 'tol':[1e-4, 5e-4, 1e-5], \n",
        "                 'ccp_alpha':[0.0, 0.1, 0.5, 1]}\n",
        "model = RandomizedSearchCV(boosting, param, scoring=scorer, cv=5)\n",
        "model.fit(x_train.values, y_train.values)\n",
        "print(\"*****************************************************\")\n",
        "print(model.best_params_)\n",
        "print(model.best_score_)\n",
        "model = model.best_estimator_\n",
        "pred = model.predict(x_test.values)\n",
        "\n",
        "print(\"Accuracy on testing data:\\t {:f}\".format(accuracy_score(y_test, pred)))\n",
        "print(\"F-score on testing data:\\t {:f}\".format(f1_score(y_test, pred)))\n",
        "print(\"*****************************************************\")"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      Iter       Train Loss      OOB Improve   Remaining Time \n",
            "         1           0.9357          -0.0020            0.01s\n",
            "         2           0.9101          -0.0013            0.01s\n",
            "         3           0.9357          -0.0020            0.01s\n",
            "         4           0.8820          -0.0130            0.01s\n",
            "         5           0.8648          -0.0199            0.01s\n",
            "         6           0.9377          -0.0034            0.01s\n",
            "         7           0.8953          -0.0031            0.00s\n",
            "         8           0.9236           0.0001            0.00s\n",
            "         9           0.9233          -0.0000            0.00s\n",
            "      Iter       Train Loss      OOB Improve   Remaining Time \n",
            "         1           0.9490          -0.0126            0.01s\n",
            "         2           0.9099           0.0002            0.01s\n",
            "         3           0.8496          -0.0285            0.01s\n",
            "         4           0.8631          -0.0113            0.01s\n",
            "      Iter       Train Loss      OOB Improve   Remaining Time \n",
            "         1           0.9724          -0.0340            0.01s\n",
            "         2           0.9687          -0.0251            0.01s\n",
            "         3           0.9114           0.0017            0.01s\n",
            "         4           0.9232           0.0013            0.01s\n",
            "         5           0.9231           0.0009            0.01s\n",
            "         6           0.8966          -0.0026            0.01s\n",
            "         7           0.9098           0.0001            0.00s\n",
            "         8           0.9232          -0.0009            0.00s\n",
            "         9           0.9098           0.0001            0.00s\n",
            "      Iter       Train Loss      OOB Improve   Remaining Time \n",
            "         1           0.9096          -0.0000            0.01s\n",
            "         2           0.8953          -0.0016            0.01s\n",
            "         3           0.8951          -0.0012            0.01s\n",
            "         4           0.9372          -0.0068            0.01s\n",
            "         5           0.9097           0.0000            0.01s\n",
            "         6           0.9097           0.0000            0.01s\n",
            "         7           0.9233          -0.0013            0.00s\n",
            "         8           0.9484          -0.0113            0.00s\n",
            "         9           0.8820          -0.0084            0.00s\n",
            "      Iter       Train Loss      OOB Improve   Remaining Time \n",
            "         1           0.9365          -0.0056            0.01s\n",
            "         2           0.8811          -0.0076            0.01s\n",
            "         3           0.9235          -0.0016            0.01s\n",
            "         4           0.9097           0.0000            0.01s\n",
            "         5           0.9233          -0.0013            0.01s\n",
            "         6           0.9232          -0.0010            0.01s\n",
            "         7           0.8656          -0.0161            0.00s\n",
            "      Iter       Train Loss   Remaining Time \n",
            "         1           1.2299            0.01s\n",
            "         2           1.2299            0.01s\n",
            "      Iter       Train Loss   Remaining Time \n",
            "         1           1.2091            0.01s\n",
            "         2           1.2091            0.01s\n",
            "      Iter       Train Loss   Remaining Time \n",
            "         1           1.2091            0.01s\n",
            "         2           1.2091            0.01s\n",
            "      Iter       Train Loss   Remaining Time \n",
            "         1           1.2091            0.01s\n",
            "         2           1.2091            0.01s\n",
            "      Iter       Train Loss   Remaining Time \n",
            "         1           1.2091            0.01s\n",
            "         2           1.2091            0.01s\n",
            "      Iter       Train Loss      OOB Improve   Remaining Time \n",
            "         1           1.2320          -0.0000            0.26s\n",
            "         2           1.3626          -0.0051            0.31s\n",
            "         3           1.2961          -0.0014            0.30s\n",
            "         4           1.1996           0.0000            0.29s\n",
            "         5           1.1652          -0.0007            0.29s\n",
            "         6           1.0925          -0.0038            0.29s\n",
            "         7           1.1614          -0.0009            0.28s\n",
            "         8           1.1969          -0.0001            0.28s\n",
            "         9           1.2325           0.0000            0.28s\n",
            "        10           1.1607          -0.0009            0.28s\n",
            "      Iter       Train Loss      OOB Improve   Remaining Time \n",
            "         1           1.3357          -0.0038            0.24s\n",
            "         2           1.1619          -0.0004            0.30s\n",
            "         3           1.2323          -0.0001            0.29s\n",
            "         4           1.3001          -0.0020            0.28s\n",
            "      Iter       Train Loss      OOB Improve   Remaining Time \n",
            "         1           1.2999          -0.0016            0.24s\n",
            "         2           1.1628          -0.0007            0.30s\n",
            "         3           1.1254          -0.0019            0.30s\n",
            "         4           1.1968          -0.0001            0.29s\n",
            "         5           1.2326          -0.0000            0.28s\n",
            "         6           1.3014          -0.0015            0.28s\n",
            "      Iter       Train Loss      OOB Improve   Remaining Time \n",
            "         1           1.1972          -0.0001            0.23s\n",
            "         2           1.2322          -0.0000            0.29s\n",
            "         3           1.1971          -0.0001            0.29s\n",
            "         4           1.1970          -0.0001            0.29s\n",
            "         5           1.1969          -0.0001            0.29s\n",
            "         6           1.1969          -0.0001            0.28s\n",
            "         7           1.0851          -0.0038            0.28s\n",
            "         8           1.1590          -0.0007            0.28s\n",
            "         9           1.1586          -0.0007            0.28s\n",
            "        10           1.2708          -0.0002            0.28s\n",
            "      Iter       Train Loss      OOB Improve   Remaining Time \n",
            "         1           1.2664          -0.0005            0.24s\n",
            "         2           1.2989          -0.0016            0.30s\n",
            "         3           1.1981          -0.0000            0.29s\n",
            "         4           1.2980          -0.0016            0.28s\n",
            "      Iter       Train Loss   Remaining Time \n",
            "         1           1.2154            0.07s\n",
            "         2           1.2154            0.09s\n",
            "         3           1.2154            0.09s\n",
            "         4           1.2154            0.08s\n",
            "      Iter       Train Loss   Remaining Time \n",
            "         1           1.2154            0.07s\n",
            "         2           1.2154            0.09s\n",
            "         3           1.2154            0.09s\n",
            "         4           1.2154            0.08s\n",
            "      Iter       Train Loss   Remaining Time \n",
            "         1           1.2154            0.07s\n",
            "         2           1.2154            0.09s\n",
            "         3           1.2154            0.08s\n",
            "         4           1.2154            0.08s\n",
            "      Iter       Train Loss   Remaining Time \n",
            "         1           1.2154            0.07s\n",
            "         2           1.2154            0.09s\n",
            "         3           1.2154            0.09s\n",
            "         4           1.2154            0.08s\n",
            "      Iter       Train Loss   Remaining Time \n",
            "         1           1.2154            0.07s\n",
            "         2           1.2154            0.09s\n",
            "         3           1.2154            0.09s\n",
            "         4           1.2154            0.08s\n",
            "*****************************************************\n",
            "{'warm_start': True, 'verbose': 0, 'validation_fraction': 0.8, 'tol': 0.0005, 'subsample': 0.4, 'n_iter_no_change': None, 'n_estimators': 400, 'min_weight_fraction_leaf': 0.2, 'min_samples_split': 10, 'min_samples_leaf': 12, 'min_impurity_decrease': 1.5, 'max_leaf_nodes': None, 'max_features': 'sqrt', 'max_depth': 12, 'loss': 'deviance', 'learning_rate': 0.6, 'criterion': 'mae', 'ccp_alpha': 0.1}\n",
            "0.8259302552113773\n",
            "Accuracy on testing data:\t 0.627907\n",
            "F-score on testing data:\t 0.771429\n",
            "*****************************************************\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pnPfhRW50N9R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "d6bab9ba-8007-43d4-f055-6c6ebe5b1899"
      },
      "source": [
        "features = SelectFromModel(model)\n",
        "features.fit(x_train.values, y_train.values)\n",
        "selected_feat = x_train.columns[(features.get_support())]\n",
        "xFeatTrain = x_train[selected_feat].values\n",
        "xFeatTest = x_test[selected_feat].values\n",
        "model.fit(xFeatTrain, y_train.values)\n",
        "pred = model.predict(xFeatTest)\n",
        "print(\"Accuracy on testing data:\\t {:f}\".format(accuracy_score(y_test, pred)))\n",
        "print(\"F-score on testing data:\\t {:f}\".format(f1_score(y_test, pred)))"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy on testing data:\t 0.627907\n",
            "F-score on testing data:\t 0.771429\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejirsUbz0p50",
        "colab_type": "text"
      },
      "source": [
        "## K Neighbors Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7a9k6c00nki",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "25a73537-5432-47a7-938a-d21fa989408a"
      },
      "source": [
        "neighbors = KNeighborsClassifier()\n",
        "param = {'n_neighbors':[4,5,8,10], 'weights':['uniform', 'distance'], 'algorithm':['auto', 'ball_tree', 'kd_tree', 'brute'], \n",
        "           'leaf_size':[20, 30, 50], 'p':[1,2,3], 'n_jobs':[None, -1, 1, 2, 4]}\n",
        "model = RandomizedSearchCV(neighbors, param, scoring=scorer, cv=5)\n",
        "model.fit(x_train.values, y_train.values)\n",
        "print(\"*****************************************************\")\n",
        "print(model.best_params_)\n",
        "print(model.best_score_)\n",
        "model = model.best_estimator_\n",
        "pred = model.predict(x_test.values)\n",
        "\n",
        "print(\"Accuracy on testing data:\\t {:f}\".format(accuracy_score(y_test, pred)))\n",
        "print(\"F-score on testing data:\\t {:f}\".format(f1_score(y_test, pred)))\n",
        "print(\"*****************************************************\")"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "*****************************************************\n",
            "{'weights': 'uniform', 'p': 1, 'n_neighbors': 10, 'n_jobs': None, 'leaf_size': 50, 'algorithm': 'kd_tree'}\n",
            "0.8991622477083077\n",
            "Accuracy on testing data:\t 0.790698\n",
            "F-score on testing data:\t 0.852459\n",
            "*****************************************************\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S9w8cJtL0_qd",
        "colab_type": "text"
      },
      "source": [
        "## SGD Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fnODNJvF08qs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "ff0b1a14-68c1-4f6d-bbfd-ea55b77a8bf9"
      },
      "source": [
        "sgd = SGDClassifier()\n",
        "param = {'loss':['hinge', 'log', 'modified_huber', 'squared_hinge', 'perceptron', 'squared_loss', \n",
        "                    'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive'], \n",
        "            'penalty':['l2', 'l1', 'elasticnet', 'none'], 'alpha':[0.0001, 0.001, 0.005], \n",
        "            'l1_ratio':[0, 0.15, 0.5, 0.7], 'fit_intercept':[True, False], \n",
        "            'max_iter':[500, 1000, 1500],'tol':[1e-4, 5e-4, 1e-5], 'epsilon':[0.1, 0.3,  0.5], \n",
        "            'n_jobs':[-1, 1, 2, 4], \n",
        "            'power_t':[0.5,0.8, 0.4], 'early_stopping':[True, False],'validation_fraction':[0.1, 0.4, 0.8], \n",
        "            'n_iter_no_change':[ 1, 2, 3, 4], 'warm_start':[True, False]}\n",
        "model = RandomizedSearchCV(sgd, param, scoring=scorer, cv=5)\n",
        "model.fit(x_train.values, y_train.values)\n",
        "print(\"*****************************************************\")\n",
        "print(model.best_params_)\n",
        "print(model.best_score_)\n",
        "model = model.best_estimator_\n",
        "pred = model.predict(x_test.values)\n",
        "\n",
        "print(\"Accuracy on testing data:\\t {:f}\".format(accuracy_score(y_test, pred)))\n",
        "print(\"F-score on testing data:\\t {:f}\".format(f1_score(y_test, pred)))\n",
        "print(\"*****************************************************\")"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "*****************************************************\n",
            "{'warm_start': True, 'validation_fraction': 0.1, 'tol': 1e-05, 'power_t': 0.8, 'penalty': 'l2', 'n_jobs': 4, 'n_iter_no_change': 4, 'max_iter': 500, 'loss': 'hinge', 'l1_ratio': 0.15, 'fit_intercept': True, 'epsilon': 0.3, 'early_stopping': True, 'alpha': 0.001}\n",
            "0.9103821127113052\n",
            "Accuracy on testing data:\t 0.790698\n",
            "F-score on testing data:\t 0.836364\n",
            "*****************************************************\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_FfGZfI1dhg",
        "colab_type": "text"
      },
      "source": [
        "## Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPz_dhgV1bR8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "outputId": "1f14963a-5f7d-480e-f72f-366e9cff5533"
      },
      "source": [
        "logistic = LogisticRegression()\n",
        "param = {'penalty':['l2', 'l1', 'elasticnet', 'none'], 'dual':[True, False], 'tol':[1e-4, 5e-4, 1e-5], \n",
        "                 'C':[0.5, 1.0, 1.5, 2.0], 'fit_intercept':[True, False], 'solver':['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'], \n",
        "                 'max_iter':[500, 1000, 1500], 'multi_class':['auto', 'ovr', 'multinomial'], 'verbose':[0,1], \n",
        "                 'warm_start':[True, False], 'n_jobs':[None, -1, 1, 2, 4]}\n",
        "model = RandomizedSearchCV(logistic, param, scoring=scorer, cv=5)\n",
        "model.fit(x_train.values, y_train.values)\n",
        "print(\"*****************************************************\")\n",
        "print(model.best_params_)\n",
        "print(model.best_score_)\n",
        "model = model.best_estimator_\n",
        "pred = model.predict(x_test.values)\n",
        "\n",
        "print(\"Accuracy on testing data:\\t {:f}\".format(accuracy_score(y_test, pred)))\n",
        "print(\"F-score on testing data:\\t {:f}\".format(f1_score(y_test, pred)))\n",
        "print(\"*****************************************************\")"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]*****************************************************\n",
            "{'warm_start': True, 'verbose': 1, 'tol': 0.0001, 'solver': 'liblinear', 'penalty': 'l2', 'n_jobs': 2, 'multi_class': 'auto', 'max_iter': 1000, 'fit_intercept': False, 'dual': True, 'C': 0.5}\n",
            "0.9293374667320874\n",
            "Accuracy on testing data:\t 0.813953\n",
            "F-score on testing data:\t 0.857143\n",
            "*****************************************************\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08OZP5hB2oau",
        "colab_type": "text"
      },
      "source": [
        "## OUTCOMES\n",
        "\n",
        "So, outcomes are as follows : \n",
        "\n",
        "Accuracy and f1-score values of different models are as follows:\n",
        "\n",
        "> The highes the accuracy and f1-score better the model is.\n",
        "\n",
        "1.   Logistic Regression (no params passed) : \n",
        "    *   Accuracy on testing data:\t 0.697674\n",
        "    *   F-score on testing data:\t 0.779661\n",
        "2.  Gaussian Naive Bayes :\n",
        "    *   Accuracy on testing data:\t 0.744186\n",
        "    *   F-score on testing data:\t 0.792453\n",
        "    * Params : ```{'var_smoothing': 1e-09}```\n",
        "3. Decision Tree (without feature selection) : \n",
        "    *   Accuracy on testing data:\t 0.627907\n",
        "    *   F-score on testing data:\t 0.771429\n",
        "    * Params : ```{'splitter': 'best', 'min_weight_fraction_leaf': 0.1, 'min_samples_split': 2, 'min_samples_leaf': 9, 'min_impurity_decrease': 1.0, 'max_leaf_nodes': None, 'max_features': 'sqrt', 'max_depth': None, 'criterion': 'entropy'}```\n",
        "\n",
        "4. Decision Tree (with feature selection) : \n",
        "    * Accuracy on testing data:\t 0.627907\n",
        "    * F-score on testing data:\t 0.771429\n",
        "5. Bagging Classifier : \n",
        "    * Accuracy on testing data:\t 0.627907\n",
        "    * F-score on testing data:\t 0.771429\n",
        "    * Params : ```{'warm_start': False, 'verbose': 0, 'oob_score': True, 'n_jobs': 2, 'n_estimators': 10, 'max_samples': 100, 'max_features': 2, 'bootstrap_features': False, 'bootstrap': True}```\n",
        "6. AdaBoost (without feature selection) : \n",
        "    * Accuracy on testing data:\t 0.790698\n",
        "    * F-score on testing data:\t 0.842105\n",
        "    * Params : ```{'n_estimators': 200, 'learning_rate': 1.5, 'algorithm': 'SAMME'}```\n",
        "7. AdaBoost (with feature selection) : \n",
        "    * Accuracy on testing data:\t 0.767442\n",
        "    * F-score on testing data:\t 0.821429\n",
        "8. Random Forest : \n",
        "    * Accuracy on testing data:\t 0.627907\n",
        "    * F-score on testing data:\t 0.771429\n",
        "    * Params : ```{'warm_start': False, 'verbose': 1, 'oob_score': True, 'n_jobs': 1, 'n_estimators': 200, 'min_weight_fraction_leaf': 0.1, 'min_samples_split': 30, 'min_samples_leaf': 9, 'min_impurity_decrease': 1.5, 'max_samples': 1, 'max_leaf_nodes': 100, 'max_features': 'sqrt', 'max_depth': None, 'criterion': 'entropy', 'class_weight': 'balanced', 'ccp_alpha': 0.0, 'bootstrap': True}```\n",
        "9. Gradient Boosting (without feature selection) : \n",
        "    * Accuracy on testing data:\t 0.627907\n",
        "    * F-score on testing data:\t 0.771429\n",
        "    * Params : ```{'warm_start': True, 'verbose': 0, 'validation_fraction': 0.8, 'tol': 0.0005, 'subsample': 0.4, 'n_iter_no_change': None, 'n_estimators': 400, 'min_weight_fraction_leaf': 0.2, 'min_samples_split': 10, 'min_samples_leaf': 12, 'min_impurity_decrease': 1.5, 'max_leaf_nodes': None, 'max_features': 'sqrt', 'max_depth': 12, 'loss': 'deviance', 'learning_rate': 0.6, 'criterion': 'mae', 'ccp_alpha': 0.1}```\n",
        "10. Gradient Boosting (with feature selection) : \n",
        "    * Accuracy on testing data:\t 0.627907\n",
        "    * F-score on testing data:\t 0.771429\n",
        "11. K Neighbors : \n",
        "    * Accuracy on testing data:\t 0.790698\n",
        "    * F-score on testing data:\t 0.852459\n",
        "    * Params : ```{'weights': 'uniform', 'p': 1, 'n_neighbors': 10, 'n_jobs': None, 'leaf_size': 50, 'algorithm': 'kd_tree'}```\n",
        "12. SGD : \n",
        "    * Accuracy on testing data:\t 0.790698\n",
        "    * F-score on testing data:\t 0.836364\n",
        "    * Params : ```{'warm_start': True, 'validation_fraction': 0.1, 'tol': 1e-05, 'power_t': 0.8, 'penalty': 'l2', 'n_jobs': 4, 'n_iter_no_change': 4, 'max_iter': 500, 'loss': 'hinge', 'l1_ratio': 0.15, 'fit_intercept': True, 'epsilon': 0.3, 'early_stopping': True, 'alpha': 0.001}```\n",
        "13. Logistic Regression : \n",
        "    * Accuracy on testing data:\t 0.813953\n",
        "    * F-score on testing data:\t 0.857143\n",
        "    * Params : ```{'warm_start': True, 'verbose': 1, 'tol': 0.0001, 'solver': 'liblinear', 'penalty': 'l2', 'n_jobs': 2, 'multi_class': 'auto', 'max_iter': 1000, 'fit_intercept': False, 'dual': True, 'C': 0.5}```\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PnbM5gj521c5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}